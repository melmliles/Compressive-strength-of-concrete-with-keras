{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Let's start by importing the libraries that we will need to build our regressoin model","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-24T08:09:28.053904Z","iopub.execute_input":"2021-10-24T08:09:28.054312Z","iopub.status.idle":"2021-10-24T08:09:28.060036Z","shell.execute_reply.started":"2021-10-24T08:09:28.054272Z","shell.execute_reply":"2021-10-24T08:09:28.059235Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**PART A**","metadata":{}},{"cell_type":"markdown","source":"Let's download the data and read it into a pandas dataframe.","metadata":{}},{"cell_type":"code","source":"concrete_data = pd.read_csv('../input/regression-with-neural-networking/concrete_data.csv')\nconcrete_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:09:28.066111Z","iopub.execute_input":"2021-10-24T08:09:28.066647Z","iopub.status.idle":"2021-10-24T08:09:28.099983Z","shell.execute_reply.started":"2021-10-24T08:09:28.066613Z","shell.execute_reply":"2021-10-24T08:09:28.099251Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"The target variable in this problem is the concrete sample strength. Therefore, our predictors will be all the other columns.","metadata":{}},{"cell_type":"code","source":"concrete_data_columns = concrete_data.columns\n\npredictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\ntarget = concrete_data['Strength'] # Strength column","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:09:28.102118Z","iopub.execute_input":"2021-10-24T08:09:28.103064Z","iopub.status.idle":"2021-10-24T08:09:28.109618Z","shell.execute_reply.started":"2021-10-24T08:09:28.103024Z","shell.execute_reply":"2021-10-24T08:09:28.108794Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#Let's save the number of predictors to n_cols since we will need this number when building our network.\nn_cols = predictors.shape[1] # number of predictors","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:09:28.110913Z","iopub.execute_input":"2021-10-24T08:09:28.111289Z","iopub.status.idle":"2021-10-24T08:09:28.122055Z","shell.execute_reply.started":"2021-10-24T08:09:28.111255Z","shell.execute_reply":"2021-10-24T08:09:28.121169Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"Let's Define the regression model\n\n*Network Properties:\n\n-Hidden Layer: 1\n\n-Nodes: 10\n\n-Activation Function: ReLU\n\n-Optimizer: Adam\n\n-Loss Function: Mean Squared Error\n\n-Epochs: 50","metadata":{}},{"cell_type":"code","source":"# define regression model\ndef regression_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n    model.add(Dense(1))\n    \n    # compile model\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:09:28.123829Z","iopub.execute_input":"2021-10-24T08:09:28.124650Z","iopub.status.idle":"2021-10-24T08:09:28.134925Z","shell.execute_reply.started":"2021-10-24T08:09:28.124613Z","shell.execute_reply":"2021-10-24T08:09:28.134018Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Next, we will train the model using the fit method. We will leave out 30% of the data for test and we will train the model for 50 epochs and repeat these steps 50 times","metadata":{}},{"cell_type":"code","source":"mse = []\n\nfor i in range(50):\n    \n    #Split Data to Train and Test Set\n    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3)\n\n    # build the model\n    model = regression_model()\n\n    #fit the model\n    model.fit(X_train, y_train, epochs=50, verbose=0)\n\n    #predict output on test set\n    y_pred = model.predict(X_test)\n    \n    mse.append(mean_squared_error(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:09:28.136666Z","iopub.execute_input":"2021-10-24T08:09:28.137084Z","iopub.status.idle":"2021-10-24T08:11:00.090695Z","shell.execute_reply.started":"2021-10-24T08:09:28.136928Z","shell.execute_reply":"2021-10-24T08:11:00.089875Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#the mean squared errors of the 50 iterations:\nprint('number of iterations: {:.2f}'.format(len(mse)))\nmse","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:11:00.091931Z","iopub.execute_input":"2021-10-24T08:11:00.092324Z","iopub.status.idle":"2021-10-24T08:11:00.100851Z","shell.execute_reply.started":"2021-10-24T08:11:00.092286Z","shell.execute_reply":"2021-10-24T08:11:00.099950Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Report the mean and the standard deviation of the mean squared errors.","metadata":{}},{"cell_type":"code","source":"print('mse_Mean: {:.2f}'.format(np.mean(mse)))\nprint('mse_StdDev: {:.2f}'.format(np.std(mse)))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:11:00.103517Z","iopub.execute_input":"2021-10-24T08:11:00.104226Z","iopub.status.idle":"2021-10-24T08:11:00.115366Z","shell.execute_reply.started":"2021-10-24T08:11:00.104172Z","shell.execute_reply":"2021-10-24T08:11:00.114477Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"**PART B**","metadata":{}},{"cell_type":"markdown","source":"Now we will repeat Part A but use a normalized version of the data.\n\nRecall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.","metadata":{}},{"cell_type":"code","source":"predictors_norm = (predictors - predictors.mean()) / predictors.std()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:15:16.408741Z","iopub.execute_input":"2021-10-24T08:15:16.409083Z","iopub.status.idle":"2021-10-24T08:15:16.420233Z","shell.execute_reply.started":"2021-10-24T08:15:16.409048Z","shell.execute_reply":"2021-10-24T08:15:16.419496Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"mse = []\n\nfor i in range(50):\n    \n    #Split Data to Train and Test Set\n    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n\n    # build the model\n    model = regression_model()\n\n    #fit the model\n    model.fit(X_train, y_train, epochs=50, verbose=0)\n\n    #predict output on test set\n    y_pred = model.predict(X_test)\n    \n    mse.append(mean_squared_error(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:15:19.632543Z","iopub.execute_input":"2021-10-24T08:15:19.633088Z","iopub.status.idle":"2021-10-24T08:16:53.179515Z","shell.execute_reply.started":"2021-10-24T08:15:19.633035Z","shell.execute_reply":"2021-10-24T08:16:53.178510Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#the mean squared errors of the 50 iterations:\nprint('number of iterations: {:.2f}'.format(len(mse)))\nmse","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:17:25.594445Z","iopub.execute_input":"2021-10-24T08:17:25.595304Z","iopub.status.idle":"2021-10-24T08:17:25.604427Z","shell.execute_reply.started":"2021-10-24T08:17:25.595267Z","shell.execute_reply":"2021-10-24T08:17:25.603413Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"The mean and the standard deviation of the mean squared errors using the normalized data.","metadata":{}},{"cell_type":"code","source":"print('mse_Mean: {:.2f}'.format(np.mean(mse)))\nprint('mse_StdDev: {:.2f}'.format(np.std(mse)))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:17:30.615146Z","iopub.execute_input":"2021-10-24T08:17:30.615957Z","iopub.status.idle":"2021-10-24T08:17:30.621951Z","shell.execute_reply.started":"2021-10-24T08:17:30.615918Z","shell.execute_reply":"2021-10-24T08:17:30.621137Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"We can see that normalizing the data has a huge impact on the results, we have now a low standard deviation which means that data are clustered around the mean","metadata":{}},{"cell_type":"markdown","source":"**PART C**","metadata":{}},{"cell_type":"markdown","source":"We will repeat Part B but use 100 epochs this time for training.\n\n*Network Properties:\n\n-Hidden Layer: 1\n\n-Nodes: 10\n\n-Activation Function: ReLU\n\n-Optimizer: Adam\n\n-Loss Function: Mean Squared Error\n\n-Epochs: 100","metadata":{}},{"cell_type":"code","source":"mse = []\n\nfor i in range(50):\n    \n    #Split Data to Train and Test Set\n    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n\n    # build the model\n    model = regression_model()\n\n    #fit the model\n    model.fit(X_train, y_train, epochs=100, verbose=0)\n\n    #predict output on test set\n    y_pred = model.predict(X_test)\n    \n    mse.append(mean_squared_error(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:21:28.610711Z","iopub.execute_input":"2021-10-24T08:21:28.611641Z","iopub.status.idle":"2021-10-24T08:24:03.877976Z","shell.execute_reply.started":"2021-10-24T08:21:28.611597Z","shell.execute_reply":"2021-10-24T08:24:03.877186Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#the mean squared errors of the 50 iterations:\nprint('number of iterations: {:.2f}'.format(len(mse)))\nmse","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:40:10.396697Z","iopub.execute_input":"2021-10-24T08:40:10.397064Z","iopub.status.idle":"2021-10-24T08:40:10.406182Z","shell.execute_reply.started":"2021-10-24T08:40:10.397026Z","shell.execute_reply":"2021-10-24T08:40:10.405226Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"The mean and the standard deviation of the mean squared errors using 100 epochs.","metadata":{}},{"cell_type":"code","source":"print('mse_Mean: {:.2f}'.format(np.mean(mse)))\nprint('mse_StdDev: {:.2f}'.format(np.std(mse)))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:40:15.108926Z","iopub.execute_input":"2021-10-24T08:40:15.109435Z","iopub.status.idle":"2021-10-24T08:40:15.117614Z","shell.execute_reply.started":"2021-10-24T08:40:15.109399Z","shell.execute_reply":"2021-10-24T08:40:15.116525Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"We can see that the epochs have a huge impact on the results, the mean has changed drastically with a very low standard deviation.","metadata":{}},{"cell_type":"markdown","source":"**PART D**","metadata":{}},{"cell_type":"markdown","source":"We will repeat now part B but use a neural network with the following properties:\n\n-Hidden Layer: 3\n\n-Nodes: 10\n\n-Activation Function: ReLU\n\n-Optimizer: Adam\n\n-Loss Function: Mean Squared Error\n\n-Epochs: 50","metadata":{}},{"cell_type":"code","source":"# define regression model\ndef regression_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n    model.add(Dense(10, activation='relu'))\n    model.add(Dense(10, activation='relu'))\n    model.add(Dense(1))\n    \n    # compile model\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:48:22.139931Z","iopub.execute_input":"2021-10-24T08:48:22.140322Z","iopub.status.idle":"2021-10-24T08:48:22.147220Z","shell.execute_reply.started":"2021-10-24T08:48:22.140286Z","shell.execute_reply":"2021-10-24T08:48:22.146244Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"mse = []\n\nfor i in range(50):\n    \n    #Split Data to Train and Test Set\n    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n\n    # build the model\n    model = regression_model()\n\n    #fit the model\n    model.fit(X_train, y_train, epochs=50, verbose=0)\n\n    #predict output on test set\n    y_pred = model.predict(X_test)\n    \n    mse.append(mean_squared_error(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:49:29.160604Z","iopub.execute_input":"2021-10-24T08:49:29.160946Z","iopub.status.idle":"2021-10-24T08:51:33.377389Z","shell.execute_reply.started":"2021-10-24T08:49:29.160908Z","shell.execute_reply":"2021-10-24T08:51:33.376545Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#the mean squared errors of the 50 iterations:\nprint('number of iterations: {:.2f}'.format(len(mse)))\nmse","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:53:28.248484Z","iopub.execute_input":"2021-10-24T08:53:28.248930Z","iopub.status.idle":"2021-10-24T08:53:28.259050Z","shell.execute_reply.started":"2021-10-24T08:53:28.248860Z","shell.execute_reply":"2021-10-24T08:53:28.257862Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"The mean and the standard deviation of the mean squared errors using 3 hidden layers.","metadata":{}},{"cell_type":"code","source":"print('mse_Mean: {:.2f}'.format(np.mean(mse)))\nprint('mse_StdDev: {:.2f}'.format(np.std(mse)))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:53:33.780214Z","iopub.execute_input":"2021-10-24T08:53:33.781017Z","iopub.status.idle":"2021-10-24T08:53:33.786941Z","shell.execute_reply.started":"2021-10-24T08:53:33.780980Z","shell.execute_reply":"2021-10-24T08:53:33.786148Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"The impact of the number of hidden layers is more impoartant than the epochs as we cann see.\n\nWith more hidden layers, the mean is reffined with a relatively very low standard deviation.","metadata":{}}]}